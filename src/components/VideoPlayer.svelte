<script>
    import { currentVideoSource, currentTime, isPlaying } from '../stores/playerStore';
    import { mainTrackClips } from '../stores/timelineStore';
    import { isExporting, startExportTrigger } from '../stores/exportStore';
    import { onMount } from 'svelte';
    
    // ğŸ‘‡ å¼•å…¥ MP4 æ‰“åŒ…å™¨
    import { Muxer, ArrayBufferTarget } from 'mp4-muxer';
  
    let videoRef;
    let canvasRef;
    let lastTime = 0;
    
    // å°å‡ºé€²åº¦ (0 ~ 100)
    let exportProgress = 0;
  
    $: hasClips = $mainTrackClips.length > 0;
    $: contentDuration = hasClips 
        ? Math.max(...$mainTrackClips.map(c => c.startOffset + c.duration)) 
        : 0;
  
    // ------------------------------------------------
    // 1. å°å‡ºç›£è½
    // ------------------------------------------------
    $: if ($startExportTrigger > 0 && !$isExporting && hasClips) {
        renderVideoProcess();
    }
  
    // ------------------------------------------------
    // 2. æ ¸å¿ƒï¼šé€å¹€æ¸²æŸ“ (å«éŸ³è¨Šè™•ç†)
    // ------------------------------------------------
    async function renderVideoProcess() {
        try {
            console.log("é–‹å§‹å°å‡º (å«éŸ³è¨Š)...");
            isExporting.set(true);
            isPlaying.set(false); // åœæ­¢ UI æ’­æ”¾
            exportProgress = 0;
  
            const width = 1280;
            const height = 720;
            const fps = 30;
            const durationInSeconds = contentDuration; 
            const totalFrames = Math.ceil(durationInSeconds * fps);
            
            // é è¨­å–æ¨£ç‡ (ç¨å¾Œå¯èƒ½å› ç‚º Opus è€Œæ”¹è®Š)
            let targetSampleRate = 44100;

            // ==========================================
            // A. è¨­å®š MP4 Muxer
            // ==========================================
            // æ³¨æ„ï¼šé€™è£¡å…ˆä¸è¨­å®š audioï¼Œç­‰ç¢ºå®šç·¨ç¢¼æ ¼å¼å¾Œå†åŠ 
            const muxer = new Muxer({
                target: new ArrayBufferTarget(),
                video: { codec: 'avc', width, height },
                audio: { codec: 'aac', numberOfChannels: 2, sampleRate: targetSampleRate }, // é è¨­ AAC
                fastStart: false 
            });
  
            // ==========================================
            // B. è¨­å®š Video Encoder
            // ==========================================
            const videoEncoder = new VideoEncoder({
                output: (chunk, meta) => muxer.addVideoChunk(chunk, meta),
                error: (e) => { throw e; }
            });
            const videoConfig = {
                codec: 'avc1.42001f', 
                width, height, bitrate: 5_000_000, framerate: fps
            };
            const vSupport = await VideoEncoder.isConfigSupported(videoConfig);
            if (!vSupport.supported) throw new Error(`ä¸æ”¯æ´è¦–è¨Šç·¨ç¢¼: ${videoConfig.codec}`);
            videoEncoder.configure(videoConfig);
  
            // ==========================================
            // C. è¨­å®š Audio Encoder (AAC å„ªå…ˆï¼ŒOpus å‚™æ´)
            // ==========================================
            const audioEncoder = new AudioEncoder({
                output: (chunk, meta) => muxer.addAudioChunk(chunk, meta),
                error: (e) => console.error("Audio Encoding Error:", e)
            });
            
            // 1. å„ªå…ˆå˜—è©¦ AAC (ç›¸å®¹æ€§æœ€å¥½)
            let audioConfig = {
                codec: 'mp4a.40.2', // AAC LC
                sampleRate: 44100,
                numberOfChannels: 2,
                bitrate: 128_000
            };
            
            let aSupport = await AudioEncoder.isConfigSupported(audioConfig);
            
            // 2. å¦‚æœä¸æ”¯æ´ AAC (ä¾‹å¦‚ Linux)ï¼Œå˜—è©¦ Opus
            if (!aSupport.supported) {
                console.warn("ä¸æ”¯æ´ AACï¼Œå˜—è©¦åˆ‡æ›è‡³ Opus (Linux mode)...");
                audioConfig = {
                    codec: 'opus', 
                    sampleRate: 48000, // Opus å¿…é ˆæ˜¯ 48kHz
                    numberOfChannels: 2,
                    bitrate: 128_000
                };
                targetSampleRate = 48000; // æ›´æ–°å…¨åŸŸå–æ¨£ç‡
                
                // Muxer éœ€è¦é‡æ–°è¨­å®š Audio Header å—ï¼Ÿmp4-muxer æ¯”è¼ƒå¯¬å®¹ï¼Œé€šå¸¸ä¸éœ€è¦é‡å»ºç‰©ä»¶
                // ä½†æˆ‘å€‘è¦ç¢ºä¿å‚³çµ¦ Muxer çš„ sampleRate ä¹Ÿæ˜¯å°çš„ (é›–ç„¶ä¸Šé¢å·²ç¶“ new äº†)
                
                aSupport = await AudioEncoder.isConfigSupported(audioConfig);
            }

            if (!aSupport.supported) {
                console.error("ç€è¦½å™¨æ—¢ä¸æ”¯æ´ AAC ä¹Ÿä¸æ”¯æ´ Opusï¼Œå°å‡ºå°‡ç„¡è²ã€‚");
            } else {
                console.log(`ä½¿ç”¨éŸ³è¨Šç·¨ç¢¼: ${audioConfig.codec}, SampleRate: ${targetSampleRate}`);
                audioEncoder.configure(audioConfig);
            }

            // ==========================================
            // D. è™•ç†éŸ³è¨Š (æ··éŸ³ -> ç·¨ç¢¼)
            // ==========================================
            // ==========================================
            // D. è™•ç†éŸ³è¨Š (æ··éŸ³ -> åˆ‡ç‰‡ -> ç·¨ç¢¼)
            // ==========================================
            if (aSupport.supported) {
                console.log("æ­£åœ¨è™•ç†éŸ³è¨Šæ··éŸ³...");
                
                const mixedAudioBuffer = await mixAllAudio($mainTrackClips, durationInSeconds, targetSampleRate);
                
                const left = mixedAudioBuffer.getChannelData(0);
                const right = mixedAudioBuffer.getChannelData(1);
                const interleavedData = interleave(left, right);
                const totalSamples = mixedAudioBuffer.length;

                // ğŸ”¥ é‡å¤§ä¿®æ­£ï¼šå°‡éŸ³è¨Šåˆ‡æˆå°å¡Š (Chunking)
                // å»ºè­°æ¯å¡Šç´„ 1 ç§’ (å³ sampleRate å€‹æ¨£æœ¬)ï¼Œé¿å…ç·¨ç¢¼å™¨æ¶ˆåŒ–ä¸è‰¯
                const chunkSize = targetSampleRate; 
                
                for (let i = 0; i < totalSamples; i += chunkSize) {
                    // 1. è¨ˆç®—ç•¶å‰å¡Šçš„é•·åº¦ (æœ€å¾Œä¸€å¡Šå¯èƒ½ä¸è¶³ 1 ç§’)
                    const length = Math.min(chunkSize, totalSamples - i);
                    
                    // 2. åˆ‡å‰²æ•¸æ“š (æ³¨æ„ï¼šInterleaved æ•¸æ“šæ˜¯ L,R,L,R... æ‰€ä»¥é•·åº¦è¦ * 2)
                    const chunkData = interleavedData.slice(i * 2, (i + length) * 2);

                    // 3. è¨ˆç®—æ™‚é–“æˆ³ (å¾®ç§’)
                    const timestamp = (i / targetSampleRate) * 1_000_000;

                    // 4. å»ºç«‹ AudioData
                    const audioData = new AudioData({
                        format: 'f32', 
                        sampleRate: targetSampleRate,
                        numberOfFrames: length, // é€™ä¸€å¡Šæœ‰å¤šå°‘å¹€
                        numberOfChannels: 2,
                        timestamp: timestamp,   // é€™ä¸€å¡Šçš„æ™‚é–“é»
                        data: chunkData
                    });

                    // 5. ç·¨ç¢¼é€™ä¸€å¡Š
                    audioEncoder.encode(audioData);
                    audioData.close(); // é‡‹æ”¾è¨˜æ†¶é«”
                }
                
                // ç­‰å¾…æ‰€æœ‰å°å¡Šç·¨ç¢¼å®Œæˆ
                await audioEncoder.flush();
                console.log("éŸ³è¨Šè™•ç†å®Œæˆï¼");
            }

            // ==========================================
            // E. è™•ç†å½±åƒ (é€å¹€ç¹ªè£½)
            // ==========================================
            const ctx = canvasRef.getContext('2d', { willReadFrequently: true });
            canvasRef.width = width;
            canvasRef.height = height;

            for (let i = 0; i < totalFrames; i++) {
                const timeInSeconds = i / fps;
                const timestampMicros = i * (1_000_000 / fps);

                exportProgress = Math.round((i / totalFrames) * 100);
                await new Promise(r => setTimeout(r, 0));

                const activeClip = $mainTrackClips.find(clip => 
                    timeInSeconds >= clip.startOffset && 
                    timeInSeconds < (clip.startOffset + clip.duration)
                );

                ctx.fillStyle = '#000'; 
                ctx.fillRect(0, 0, width, height);

                if (activeClip) {
                    if (!videoRef.src.includes(activeClip.fileUrl)) {
                        videoRef.src = activeClip.fileUrl;
                        await new Promise((resolve, reject) => {
                            videoRef.onloadedmetadata = resolve;
                            videoRef.onerror = reject;
                        });
                    }

                    const seekTime = timeInSeconds - activeClip.startOffset;

                    await new Promise((resolve, reject) => {
                        const onSeeked = () => {
                            videoRef.removeEventListener('seeked', onSeeked);
                            videoRef.removeEventListener('error', onError);
                            resolve();
                        };
                        const onError = (e) => {
                            videoRef.removeEventListener('seeked', onSeeked);
                            videoRef.removeEventListener('error', onError);
                            reject(new Error("Video Seek Failed"));
                        };
                        videoRef.addEventListener('seeked', onSeeked);
                        videoRef.addEventListener('error', onError);
                        videoRef.currentTime = seekTime;
                    });

                    // ç•«é¢æ¯”ä¾‹ä¿®æ­£ (Object Fit: Contain)
                    const vw = videoRef.videoWidth;
                    const vh = videoRef.videoHeight;
                    const videoRatio = vw / vh;
                    const canvasRatio = width / height;
                    let drawW, drawH;
                    if (videoRatio > canvasRatio) {
                        drawW = width;
                        drawH = width / videoRatio;
                    } else {
                        drawH = height;
                        drawW = height * videoRatio;
                    }
                    const offsetX = (width - drawW) / 2;
                    const offsetY = (height - drawH) / 2;
                    ctx.drawImage(videoRef, offsetX, offsetY, drawW, drawH);
                }

                const frame = new VideoFrame(canvasRef, { timestamp: timestampMicros });
                const keyFrame = i % (fps * 2) === 0; 
                videoEncoder.encode(frame, { keyFrame });
                frame.close();
            }

            // ==========================================
            // F. çµæŸèˆ‡ä¸‹è¼‰
            // ==========================================
            await videoEncoder.flush();
            muxer.finalize();

            const { buffer } = muxer.target;
            const blob = new Blob([buffer], { type: 'video/mp4' });
            const url = URL.createObjectURL(blob);
            
            const a = document.createElement('a');
            a.href = url;
            a.download = `capcut_export_${Date.now()}.mp4`;
            document.body.appendChild(a);
            a.click();
            
            setTimeout(() => {
                document.body.removeChild(a);
                window.URL.revokeObjectURL(url);
                isExporting.set(false);
                startExportTrigger.set(0);
            }, 1000);

        } catch (err) {
            console.error("Export Error:", err);
            alert(`Export Failed: ${err.message}`);
            isExporting.set(false);
            startExportTrigger.set(0);
        }
    }
  
  
    // ------------------------------------------------
    // 3. UI æ’­æ”¾é‚è¼¯ (Preview Mode)
    // ------------------------------------------------
    
    $: activeClip = $mainTrackClips.find(clip => 
        $currentTime >= clip.startOffset && 
        $currentTime < (clip.startOffset + clip.duration)
    );
  
    $: if (videoRef && activeClip && !$isExporting) {
        if (!videoRef.src.includes(activeClip.fileUrl)) {
            videoRef.src = activeClip.fileUrl;
        }
        const seekTime = $currentTime - activeClip.startOffset;
        if (Math.abs(videoRef.currentTime - seekTime) > 0.2) {
            videoRef.currentTime = seekTime;
        }
    }
  
    function togglePlay() {
        if (!hasClips || $isExporting) return;
        if (!$isPlaying && $currentTime >= contentDuration) currentTime.set(0);
        isPlaying.update(v => !v);
    }
  
    $: if ($isPlaying && !$isExporting) {
        lastTime = performance.now();
        requestAnimationFrame(loop);
        if (videoRef) videoRef.play().catch(() => {}); 
    } else {
        if (videoRef && !$isExporting) videoRef.pause();
    }
  
    $: if ($isPlaying && hasClips && $currentTime >= contentDuration && !$isExporting) {
        isPlaying.set(false);
        currentTime.set(contentDuration);
    }
  
    function loop(timestamp) {
        if (!$isPlaying || $isExporting) return;
        const deltaTime = (timestamp - lastTime) / 1000;
        lastTime = timestamp;
        currentTime.update(t => t + deltaTime);
        requestAnimationFrame(loop);
    }
  
    function handleDragStart(e) { if (!activeClip) e.preventDefault(); }

    // ------------------------------------------------
    // 4. éŸ³è¨Šè™•ç†å·¥å…·å‡½æ•¸ (Audio Helpers)
    // ------------------------------------------------

    async function mixAllAudio(clips, totalDuration, targetSampleRate = 44100) {
        const sampleRate = targetSampleRate; 
        
        // OfflineAudioContext ç”¨æ–¼å¿«é€Ÿæ¸²æŸ“è²éŸ³
        const offlineCtx = new OfflineAudioContext(2, Math.ceil(totalDuration * sampleRate), sampleRate);

        const promises = clips.map(async (clip) => {
            try {
                const response = await fetch(clip.fileUrl);
                const arrayBuffer = await response.arrayBuffer();
                
                const tempCtx = new AudioContext();
                const audioBuffer = await tempCtx.decodeAudioData(arrayBuffer);
                tempCtx.close(); 

                const source = offlineCtx.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(offlineCtx.destination);
                source.start(clip.startOffset);
                
                if (clip.duration < audioBuffer.duration) {
                    source.stop(clip.startOffset + clip.duration);
                }
            } catch (e) {
                console.warn(`ç„¡æ³•è™•ç†éŸ³è¨Š: ${clip.name}`, e);
            }
        });

        await Promise.all(promises);
        const renderedBuffer = await offlineCtx.startRendering();
        return renderedBuffer;
    }

    function interleave(inputL, inputR) {
        const length = inputL.length + inputR.length;
        const result = new Float32Array(length);

        let index = 0;
        let inputIndex = 0;

        while (index < length) {
            result[index++] = inputL[inputIndex];
            result[index++] = inputR[inputIndex];
            inputIndex++;
        }
        return result;
    }
</script>

<div class="flex-1 bg-[#101010] relative flex flex-col justify-center items-center overflow-hidden w-full h-full select-none">
  
    <canvas bind:this={canvasRef} class="hidden"></canvas>

    <div class="relative w-full h-full flex justify-center items-center group" on:click={togglePlay}>
      
        <video 
            bind:this={videoRef}
            class="max-w-full max-h-full object-contain pointer-events-none {activeClip ? 'block' : 'hidden'}" 
            muted={false}
            crossorigin="anonymous"
        ></video>
        
        {#if activeClip && !$isExporting}
            <div class="absolute top-4 left-4 bg-black/50 px-2 py-1 rounded text-xs text-white z-20">Playing: {activeClip.name}</div>
        {/if}

        {#if !activeClip}
            <div class="flex flex-col items-center gap-4 opacity-20 text-white absolute">
                <span class="text-sm">{!hasClips ? 'Drag media to start' : 'Black Screen'}</span>
            </div>
        {/if}

        {#if !$isPlaying && hasClips && !$isExporting}
            <div class="absolute z-50 bg-black/50 p-4 rounded-full backdrop-blur-sm pointer-events-none">
            <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24" fill="white" stroke="none"><polygon points="5 3 19 12 5 21 5 3"/></svg>
            </div>
        {/if}
      
        {#if $isExporting}
            <div class="absolute z-50 bg-black/90 px-8 py-6 rounded-xl flex flex-col items-center gap-4 shadow-2xl border border-gray-800">
                <div class="relative w-12 h-12">
                    <div class="absolute inset-0 border-4 border-gray-700 rounded-full"></div>
                    <div class="absolute inset-0 border-4 border-cyan-500 border-t-transparent rounded-full animate-spin"></div>
                </div>
                <div class="text-center">
                    <div class="text-white font-bold text-lg">Exporting MP4...</div>
                    <div class="text-cyan-400 font-mono text-xl mt-1">{exportProgress}%</div>
                </div>
                <div class="text-xs text-gray-500">Do not close this tab</div>
            </div>
        {/if}
    </div>

    <div class={`absolute bottom-8 bg-[#1e1e1e] border border-gray-700 rounded-full px-6 py-2 flex items-center gap-6 text-white z-30 transition-opacity ${!hasClips || $isExporting ? 'opacity-50 cursor-not-allowed' : ''}`}>
        <button on:click|stopPropagation={togglePlay} class="hover:text-cyan-400 disabled:cursor-not-allowed" disabled={!hasClips || $isExporting}>
            {#if $isPlaying} â¸ {:else} â–¶ {/if}
        </button>
        <div class="w-[1px] h-4 bg-gray-600"></div>
        <span class="font-mono text-sm w-16 text-center">{$currentTime.toFixed(1)}s</span>
    </div>
</div>